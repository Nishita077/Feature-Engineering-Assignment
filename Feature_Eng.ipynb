{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n"
      ],
      "metadata": {
        "id": "98HEvOaWB6Oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. What is a parameter?\n",
        "\n",
        "A parameter is a variable that a machine learning model **learns from the training data** to make predictions.  \n",
        "Example: In linear regression `y = w*x + b`, `w` (weight) and `b` (bias) are parameters.\n"
      ],
      "metadata": {
        "id": "cyj72RNFCG75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2: What is correlation?\n",
        "Ans).\n",
        "Correlation is a statistical measure that describes the strength and direction of a relationship\n",
        "between two variables. It ranges from -1 to +1. A higher absolute value indicates a stronger relationship.\n",
        "\n",
        "\n",
        "# Q3: What does negative correlation mean?\n",
        "Ans).\n",
        "Negative correlation means that as one variable increases, the other variable tends to decrease.\n",
        "For example, if study hours decrease and mistakes increase, these two variables are negatively correlated.\n",
        "\n",
        "\n",
        "# Q4: Define Machine Learning. What are the main components in Machine Learning?\n",
        "Ans).\n",
        "Machine Learning is a branch of Artificial Intelligence where systems learn patterns from data\n",
        "to make predictions or decisions without being explicit programming.\n",
        "\n",
        "###Main components:\n",
        "1. Dataset - The data used for training and testing.\n",
        "2. Features - Input variables used for predictions.\n",
        "3. Model - The algorithm that learns patterns from the data.\n",
        "4. Parameters - Internal variables learned by the model.\n",
        "5. Hyperparameters - External settings that control the learning process.\n",
        "6. Evaluation Metrics - Measures that check model performance.\n",
        "\n",
        "\n",
        "# Q5: How does loss value help in determining whether the model is good or not?\n",
        "Ans).\n",
        "Loss is a numerical measure of how well the model’s predictions match the actual outcomes.\n",
        "A lower loss indicates better model performance. During training, models try to minimize this loss.\n",
        "\n",
        "# Q6: What are continuous and categorical variables?\n",
        "Ans).\n",
        "Continuous variables are numeric variables that can take any value within a range (e.g., height, temperature).\n",
        "Categorical variables are variables with distinct categories or labels (e.g., gender, color, country).\n",
        "\n",
        "\n",
        "# Q7: How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "Ans).\n",
        "Categorical variables need to be converted into numeric format for ML models. Common techniques include:\n",
        "1. Label Encoding - Assigns each category a unique integer.\n",
        "2. One-Hot Encoding - Creates binary columns for each category.\n",
        "3. Ordinal Encoding - Assigns integers based on order if the categories are ordinal.\n",
        "\n",
        "\n",
        "# Q8: What do you mean by training and testing a dataset?\n",
        "Ans).\n",
        "Training data is used to teach the model patterns from data, while testing data is used to evaluate\n",
        "how well the model generalizes to unseen data. This ensures the model is not overfitting.\n",
        "\n",
        "# Q9: What is sklearn.preprocessing?\n",
        "Ans).\n",
        "sklearn.preprocessing is a module in scikit-learn that provides functions for data preprocessing,\n",
        "such as scaling, normalization, encoding categorical variables, and transforming features to improve model performance.\n",
        "\n",
        "\n",
        "- Scaling / Normalization – adjusting numeric features to a similar scale.\n",
        "\n",
        "- Encoding categorical variables – converting non-numeric data to numeric.\n",
        "\n",
        "- Handling missing values – preprocessing techniques like imputation.\n",
        "\n",
        "- Transformations – like polynomial features, logarithmic transformations, etc.\n",
        "\n",
        "Preprocessing is important because most ML algorithms perform better when data is scaled and numeric.\n",
        "\n",
        "\n",
        "# Q10: What is a Test set?\n",
        "Ans).\n",
        "A test set is a subset of the dataset that the model has not seen during training.\n",
        "It is used to evaluate the model’s performance and generalization on unseen data.\n",
        "\n",
        "\n",
        "# Q11: How do we split data for model fitting (training and testing) in Python?\n",
        "Ans).\n",
        "In Python, we can use scikit-learn’s train_test_split function:<br>\n",
        "\n",
        "from sklearn.model_selection import train_test_split<br>\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)<br>\n",
        "\n",
        "This splits data into training (80%) and testing (20%) sets.\n",
        "\n",
        "\n",
        "# Q12: How do you approach a Machine Learning problem?\n",
        "Ans).\n",
        "1. Understand the problem and objectives.\n",
        "2. Collect and explore the data.\n",
        "3. Preprocess the data (cleaning, handling missing values, encoding).\n",
        "4. Perform exploratory data analysis (EDA) to find patterns.\n",
        "5. Choose the appropriate ML model.\n",
        "6. Train and validate the model.\n",
        "7. Evaluate the model using metrics.\n",
        "8. Optimize hyperparameters and improve performance.\n",
        "\n",
        "\n",
        "# Q13: Why do we have to perform EDA before fitting a model to the data?\n",
        "answer_q13 = \"\"\"\n",
        "EDA (Exploratory Data Analysis) helps understand data distribution, patterns, and relationships.\n",
        "It identifies missing values, outliers, and correlations, which informs preprocessing and model selection.\n",
        "\n",
        "\n",
        "# Q14: How can you find correlation between variables in Python?\n",
        "Ans).\n",
        "We can use pandas’ corr() function:\n",
        "\n",
        "(import pandas as pd\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix))\n",
        "\n",
        "This computes the Pearson correlation coefficient between numeric variables.\n",
        "\n",
        "\n",
        "# Q15: What is causation? Explain difference between correlation and causation with an example.\n",
        "Ans).\n",
        "Causation means that one variable directly causes a change in another.\n",
        "\n",
        "Difference:\n",
        "- Correlation: Measures how two variables move together, but one does not necessarily cause the other.\n",
        "- Causation: One variable directly affects the other.\n",
        "\n",
        "Example: Ice cream sales and drowning incidents are positively correlated (more ice cream sold, more drowning),\n",
        "but ice cream sales do not cause drowning. Heat in summer increases both, which is the actual cause.\n"
      ],
      "metadata": {
        "id": "WtyR_kiSEce3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Q16: What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "Ans).\n",
        "An optimizer is an algorithm used to update the model’s parameters (weights and biases) during training\n",
        "to minimize the loss function. Optimizers adjust the model in the direction that reduces error.\n",
        "\n",
        "Common types of optimizers:\n",
        "\n",
        "1. Gradient Descent (GD): Updates parameters using the full dataset gradient. Simple but can be slow.\n",
        "2. Stochastic Gradient Descent (SGD): Updates parameters using one sample at a time. Faster, introduces noise.\n",
        "3. Mini-batch Gradient Descent: Uses small batches of data for updates. Balances speed and stability.\n",
        "4. Adam (Adaptive Moment Estimation): Combines momentum and adaptive learning rate. Often used in deep learning.\n",
        "5. RMSProp: Uses squared gradients to normalize learning rates. Useful for non-stationary objectives.\n",
        "\n",
        "Example (using Keras for Adam optimizer):\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam<br>\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "\n",
        "# Q17: What is sklearn.linear_model?\n",
        "answer_q2 = \"\"\"\n",
        "sklearn.linear_model is a module in scikit-learn that contains classes for linear models.\n",
        "These models assume a linear relationship between input features and target variable.\n",
        "\n",
        "Examples:\n",
        "- LinearRegression: For predicting continuous targets.\n",
        "- LogisticRegression: For classification tasks.\n",
        "- Ridge, Lasso: Regularized linear models to prevent overfitting.\n",
        "\n",
        "# Q18: What does model.fit() do? What arguments must be given?\n",
        "Ans).\n",
        "model.fit() trains the machine learning model using the training data.\n",
        "It learns the patterns in the data and updates the model's parameters.\n",
        "\n",
        "Arguments:\n",
        "- X: Input features (2D array or DataFrame)\n",
        "- y: Target variable (1D array or Series)\n",
        "\n",
        "Example:\n",
        "from sklearn.linear_model import LinearRegression<br>\n",
        "model = LinearRegression()<br>\n",
        "model.fit(X_train, y_train)<br>\n",
        "\n",
        "# Q19: What does model.predict() do? What arguments must be given?\n",
        "Ans).\n",
        "model.predict() uses the trained model to make predictions on new or test data.\n",
        "\n",
        "Arguments:\n",
        "- X: Input features for which predictions are required.\n",
        "\n",
        "Example:<br>\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Q20: What are continuous and categorical variables?\n",
        "answer_q5 = \"\"\"\n",
        "Continuous variables are numeric variables that can take any value in a range (e.g., height, temperature).\n",
        "Categorical variables have discrete categories or labels (e.g., color, gender, city).\n",
        "\n",
        "\n",
        "# Q21: What is feature scaling? How does it help in Machine Learning?\n",
        "Ans).\n",
        "Feature scaling is the process of transforming features to a similar scale or range.\n",
        "It helps models converge faster, improves performance, and prevents features with larger magnitudes from dominating.\n",
        "\n",
        "Techniques:\n",
        "- Standardization: Scales data to mean=0, std=1\n",
        "- Min-Max Scaling: Scales data to a fixed range, usually [0,1]\n",
        "\n",
        "# Q22: How do we perform scaling in Python?\n",
        "Ans)\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_minmax = scaler.fit_transform(X)\n",
        "\"\"\"\n",
        "\n",
        "# Q23: What is sklearn.preprocessing?\n",
        "Ans).\n",
        "sklearn.preprocessing is a module in scikit-learn that provides tools for preparing and transforming data\n",
        "before feeding it to a machine learning model.\n",
        "\n",
        "It includes:\n",
        "- Scaling and normalization\n",
        "- Encoding categorical variables\n",
        "- Feature transformations\n",
        "\n",
        "# Q24: How do we split data for model fitting (training and testing) in Python?\n",
        "answer_q9 = \"\"\"\n",
        "We use train_test_split from scikit-learn to split data into training and testing sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split<br>\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\"\"\"\n",
        "\n",
        "# Q25: Explain data encoding?\n",
        "Ans).\n",
        "Data encoding is the process of converting categorical (non-numeric) data into numeric format so\n",
        "that machine learning models can process it.\n",
        "\n",
        "Common techniques:\n",
        "1. Label Encoding: Assigns an integer to each category.\n",
        "2. One-Hot Encoding: Creates binary columns for each category.\n",
        "3. Ordinal Encoding: Assigns integers based on a defined order.\n",
        "\n"
      ],
      "metadata": {
        "id": "X_rI0jPpM07Y"
      }
    }
  ]
}